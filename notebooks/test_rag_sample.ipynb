{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4702fd-10d7-4482-abcb-bced0583576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a financial analyst assistant for CrediTrust. Your task is to answer questions about customer complaints. Use the following retrieved complaint excerpts to formulate your answer. If the context doesn't contain the answer, say you don't have enough information.\n",
      "\n",
      "Context:\n",
      "I used BNPL and was charged late fees even though I paid on time.\n",
      "---\n",
      "The BNPL interest calculation was not transparent.\n",
      "---\n",
      "Customer service was unhelpful when I disputed my BNPL charge.\n",
      "---\n",
      "I didn‚Äôt understand the repayment schedule of the BNPL loan.\n",
      "---\n",
      "Hidden charges were applied to my BNPL transaction.\n",
      "\n",
      "Question: Why are customers unhappy with BNPL?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from src.prompt_template import build_prompt\n",
    "\n",
    "dummy_chunks = [\n",
    "    \"I used BNPL and was charged late fees even though I paid on time.\",\n",
    "    \"The BNPL interest calculation was not transparent.\",\n",
    "    \"Customer service was unhelpful when I disputed my BNPL charge.\",\n",
    "    \"I didn‚Äôt understand the repayment schedule of the BNPL loan.\",\n",
    "    \"Hidden charges were applied to my BNPL transaction.\"\n",
    "]\n",
    "\n",
    "test_question = \"Why are customers unhappy with BNPL?\"\n",
    "\n",
    "prompt = build_prompt(test_question, dummy_chunks)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f61732-fe43-4a82-a1f7-ce3775d2b875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947c8d2594ed4e818df67442d219abd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Generated Answer:\n",
      " Hidden charges were applied to my BNPL transaction.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use a small model for faster response ‚Äî you can replace this with a bigger one like Mistral or Llama if supported locally\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# Run on the prompt generated earlier\n",
    "response = generator(prompt, max_new_tokens=100)[0][\"generated_text\"]\n",
    "\n",
    "print(\"üîç Generated Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9392cb0a-1a26-411d-9d76-7d2113fe18c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
